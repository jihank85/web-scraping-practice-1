{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Title]\n",
    "\n",
    "## 주제: [구글 관련 검색어 스크래핑]\n",
    "\n",
    "### 동기: 업무 중 실제 스크래핑이 필요한 항목이 무엇인지 고민 중 키워드 광고를 위해 웹에서 관련 검색어를 노가다로 수집했던 기억이 떠올라 홍보하고자 하는 키워드 관련 검색어 스크래핑을 해보면 어떨까 도전해보았습니다.\n",
    "\n",
    "### 사용한 라이브러리\n",
    "- beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파이썬 다운로드\n",
      "파이썬 장점\n",
      "파이썬 예제\n",
      "파이썬이란\n",
      "파이썬 연산자\n",
      "파이썬 에디터\n",
      "파이썬 맵\n",
      "python download\n",
      "파이썬 뱀\n",
      "점프투파이썬\n"
     ]
    }
   ],
   "source": [
    "# 1. 구글 관련 검색어 Scraping(Keyword 변경 불가)\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "ch_driver = webdriver.Chrome('/Users/kimjihan/documents/chromedriver')\n",
    "\n",
    "url = 'https://www.google.co.kr/search?q=파이썬&rlz=1C5CHFA_enKR814KR814&oq=파이썬&aqs=chrome..69i57j69i61l3j69i65j0.2320j1j7&sourceid=chrome&ie=UTF-8'\n",
    "\n",
    "ch_driver.get(url)\n",
    "\n",
    "ch_driver_html = ch_driver.page_source\n",
    "\n",
    "soup = BeautifulSoup(ch_driver_html, 'html.parser')\n",
    "\n",
    "rel_keywords = soup.find_all('p', attrs = {'class' : 'nVcaUb'})\n",
    "\n",
    "for word in rel_keywords:\n",
    "\n",
    "    print(word.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파이썬 다운로드\n",
      "파이썬 장점\n",
      "파이썬 예제\n",
      "파이썬이란\n",
      "파이썬 연산자\n",
      "파이썬 에디터\n",
      "파이썬 맵\n",
      "python download\n",
      "파이썬 뱀\n",
      "점프투파이썬\n"
     ]
    }
   ],
   "source": [
    "# 2. 구글 관련 검색어 Scraping(Keyword 변경 가능)\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "ch_driver = webdriver.Chrome('/Users/kimjihan/documents/chromedriver')\n",
    "\n",
    "keyword = '파이썬'\n",
    "\n",
    "url = 'https://www.google.co.kr/search?q='+keyword+'&rlz=1C5CHFA_enKR814KR814&oq='+keyword+'&aqs=chrome..69i57j69i61l3j69i65j0.2320j1j7&sourceid=chrome&ie=UTF-8'\n",
    "\n",
    "ch_driver.get(url)\n",
    "\n",
    "ch_driver_html = ch_driver.page_source\n",
    "\n",
    "soup = BeautifulSoup(ch_driver_html, 'html.parser')\n",
    "\n",
    "rel_keywords = soup.find_all('p', attrs = {'class' : 'nVcaUb'})\n",
    "\n",
    "for word in rel_keywords:\n",
    "\n",
    "    print(word.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 느낀 점\n",
    "복습의 중요성을 뼈져리게 느꼈습니다. 원하는 결과물을 얻기 위해 필요한 코드는 구글링을 통해 확인 할 수 있지만 실제 이 코드들이 어떠한 역할을 하고 어떨 때 써야 하는지를 파악하기는 쉽지 않았습니다. 복습을 제대로 했더라면 아마 좀 더 쉽게 각 코드가 가지고 있는 역할을 알수 있지 않았을까 합니다.\n",
    "\n",
    "### 어려웠던 점\n",
    "everything...\n",
    "\n",
    "### 보완할 부분\n",
    "사실 관련 검색어 스크래핑 시, 하나의 키워드에 대한 관련 검색어를 얻는 것이 최종 결과물이라면 많이 아쉽습니다. 궁극적인 목적은 키워드 -> 관련 검색어 스크래핑 -> 관련 검색어의 관련 검색어 스크래핑을 반복해서 자동화할 수 있다면 좀 더 활용도가 높을 것 같습니다. \n",
    "\n",
    "### 소감\n",
    "남은 기간 열.심.히. 복습하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
